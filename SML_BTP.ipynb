{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s5WRyYpadiAS"
      },
      "source": [
        "# **SML Project: Binary Tree Predictors**\n",
        "\n",
        "*   **Author:** Matteo Onger\n",
        "*   **Date:** October 2024"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2eLQPrrgfbd"
      },
      "source": [
        "**Dataset documentation**:\n",
        "*   [Secondary Mushroom](https://archive.ics.uci.edu/dataset/848/secondary+mushroom+dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh6pPVhJLCTm"
      },
      "source": [
        "## VM Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S95Nvs8sdsQ-",
        "outputId": "e2140ef6-6a11-47ef-d9c4-02a257d78410"
      },
      "outputs": [],
      "source": [
        "# install dataset package\n",
        "!pip install ucimlrepo\n",
        "\n",
        "# download repository\n",
        "!git clone -b dev https://github.com/MatteoOnger/SML_Project.git\n",
        "\n",
        "# set working directory\n",
        "%cd /content/SML_Project/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93gz7BMvLLrX"
      },
      "source": [
        "## Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PCSp96pJdllH"
      },
      "outputs": [],
      "source": [
        "# ---- LIBRARIES ----\n",
        "import logging\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "from typing import Tuple\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "from binrandomforest import BinRandomForest\n",
        "from bintreepredictor import BinTreePredictor\n",
        "from data import DataSet\n",
        "from utils import round_wrp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nv8w9CYxnUP1"
      },
      "outputs": [],
      "source": [
        "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\", force=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LJiQJtcoUVai"
      },
      "outputs": [],
      "source": [
        "# ---- FUNCTIONS ----\n",
        "def k_folds_cross_val(\n",
        "        k :int,\n",
        "        predictor :BinRandomForest|BinTreePredictor,\n",
        "        data :pd.DataFrame,\n",
        "        shuffle :bool=True,\n",
        "        random_state :int=1,\n",
        "        verbose :bool=False\n",
        "    ) -> Tuple[float, float]:\n",
        "    \"\"\"\n",
        "    Applies the k-folds cross validation to estimate the expected risk of the predictor.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    k : int\n",
        "        Number of folds.\n",
        "    predictor : BinRandomForest | BinTreePredictor\n",
        "        Predictor that must be tested.\n",
        "    data : pd.DataFrame\n",
        "        Data used to train and test the predictor.\n",
        "    shuffle : bool, optional\n",
        "        Whether to shuffle the data before splitting into batches, by default True.\n",
        "    random_state : int, optional\n",
        "        When shuffle is True, random_state affects the ordering of the indices, which controls the randomness of each fold. \n",
        "        Otherwise, this parameter has no effect, by default 1.\n",
        "    verbose : bool, optional\n",
        "        If True, training and test errors of each fold are printed, by default False.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Tuple[float, float]\n",
        "        The tuple returned contains the average training error and the average test error.\n",
        "    \"\"\"\n",
        "    avg_train_err = 0\n",
        "    avg_test_err = 0\n",
        "\n",
        "    cv = KFold(n_splits=k, shuffle=shuffle, random_state=random_state)\n",
        "\n",
        "    for i, (train_index, test_index) in enumerate(cv.split(data)):\n",
        "        train_ds = DataSet(data.iloc[train_index], label_col=\"class\")\n",
        "        test_ds =  DataSet(data.iloc[test_index], label_col=\"class\")\n",
        "\n",
        "        train_err = predictor.fit(train_ds)\n",
        "        _, test_err = predictor.predict(test_ds)\n",
        "\n",
        "        if verbose:\n",
        "            print(f\"round {i} - training_err:{round_wrp(train_err,4)} - test_err:{round_wrp(test_err,4)}\")\n",
        "\n",
        "        avg_train_err += train_err\n",
        "        avg_test_err += test_err\n",
        "    return avg_train_err / k, avg_test_err / k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "c5_g4VGfAI-W"
      },
      "outputs": [],
      "source": [
        "# fetch datatset\n",
        "mushroom_df = fetch_ucirepo(id=848).data.original\n",
        "mushroom_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Binary Tree Predictors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4Nsv9LNoWTZC"
      },
      "outputs": [],
      "source": [
        "# use k-folds CV to estimate the expected risk of the predictors produced by setting to different values the hyper-parameters\n",
        "k = 5\n",
        "\n",
        "fixed_hyperparams = {\n",
        "    \"loss_func\":\"zero-one\", \n",
        "    \"prediction_criterion\":\"mode\",\n",
        "    \"split_criterion\":\"entropy\",\n",
        "    \"stop_criterion\":\"max_height\",\n",
        "    \"max_features\":None,\n",
        "    \"max_thresholds\":5,\n",
        "}\n",
        "\n",
        "hyperparams = [\n",
        "    {\"stop_criterion_threshold\":5},\n",
        "    {\"stop_criterion_threshold\":15},\n",
        "    {\"stop_criterion_threshold\":20},\n",
        "]\n",
        "\n",
        "results = dict()\n",
        "for i, hp in enumerate(hyperparams): \n",
        "    predictor = BinTreePredictor(**fixed_hyperparams, **hp, id=i)\n",
        "    avg_train_err, avg_test_err = k_folds_cross_val(k, predictor, mushroom_df)\n",
        "    results[i] = (avg_train_err, avg_test_err)\n",
        "\n",
        "results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8T8n9qD7QdDM"
      },
      "outputs": [],
      "source": [
        "# use nested CV to get a more precise estimate of the expected risk of the learning algo\n",
        "outer_k = 10\n",
        "inner_k = 5\n",
        "\n",
        "fixed_hyperparams = {\n",
        "    \"loss_func\":\"zero-one\", \n",
        "    \"prediction_criterion\":\"mode\",\n",
        "    \"split_criterion\":\"entropy\",\n",
        "    \"stop_criterion\":\"max_height\",\n",
        "    \"max_features\":None,\n",
        "    \"max_thresholds\":5,\n",
        "}\n",
        "\n",
        "hyperparams = [\n",
        "    {\"stop_criterion_threshold\":5},\n",
        "    {\"stop_criterion_threshold\":15},\n",
        "    {\"stop_criterion_threshold\":20},\n",
        "]\n",
        "\n",
        "outer_cv = KFold(n_splits=outer_k, shuffle=True, random_state=1)\n",
        "\n",
        "avg_train_err = 0\n",
        "avg_val_err = 0\n",
        "avg_test_err = 0\n",
        "\n",
        "for train_index, test_index in outer_cv.split(mushroom_df):\n",
        "    train_df = mushroom_df.iloc[train_index]\n",
        "    test_df = mushroom_df.iloc[test_index]\n",
        "\n",
        "    train_ds = DataSet(train_df, label_col=\"class\")\n",
        "    test_ds = DataSet(test_df, label_col=\"class\")\n",
        "\n",
        "    best_hyperparam, best_val_err = None, float(\"inf\")\n",
        "\n",
        "    for i, hp in enumerate(hyperparams): \n",
        "        predictor = BinTreePredictor(**fixed_hyperparams, **hp, id=i)\n",
        "        _, avg_val_err = k_folds_cross_val(inner_k, predictor, train_df)\n",
        "\n",
        "        if avg_val_err < best_val_err:\n",
        "            best_val_err = avg_val_err\n",
        "            best_hyperparam = hp\n",
        "\n",
        "    predictor = BinTreePredictor(**fixed_hyperparams, **hp, id=i)\n",
        "    train_err = predictor.fit(train_ds)\n",
        "    _, test_err = predictor.predict(test_ds)\n",
        "    \n",
        "    avg_train_err += train_err\n",
        "    avg_test_err += test_err\n",
        "\n",
        "avg_train_err = avg_train_err / outer_k\n",
        "avg_test_err = avg_test_err / outer_k\n",
        "\n",
        "print(f\"avg_training_err:{round_wrp(avg_train_err,4)} - avg_training_err:{round_wrp(avg_val_err,4)} - avg_test_err:{round_wrp(avg_test_err,4)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
